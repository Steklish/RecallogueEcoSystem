# Pipeline Обработки Текстов для Извлечения Графа Знаний

## Общее описание

Этот проект представляет собой pipeline для извлечения графа знаний из текстовых документов с использованием языковых моделей (LLM). Основная цель — автоматически извлекать сущности (люди, организации, места и т.д.) и отношения между ними из текстов на русском языке, а затем сохранять их в базе данных графа (Neo4j).

## Архитектура и компоненты

### 1. `parse.py` - Основной скрипт обработки
Основной входной файл, который запускает весь pipeline обработки текста.

**Основные функции:**
- Чтение текстовых файлов из заданного списка
- Обнаружение имен сущностей с помощью spaCy
- Генерация графа знаний с помощью LLM
- Нормализация сущностей и объединение дубликатов
- Сохранение результатов в базу данных Neo4j
- Генерация Cypher-запросов для импорта

**Пайплайн обработки:**
1. **Загрузка файла** - чтение содержимого текстового файла
2. **Обнаружение имен** - использование spaCy для нахождения персон, организаций и мест
3. **Получение контекста** - извлечение связанной информации из базы знаний
4. **Генерация графа знаний** - использование LLM для извлечения сущностей и связей
5. **Нормализация сущностей** - объединение схожих имен и обновление описаний
6. **Сохранение в базу данных** - запись результатов в Neo4j

### 2. `schemas.py` - Определение структуры данных
Определяет Pydantic-модели для структур данных:
- `Entity` - сущность с именем, типом, описанием и контекстом
- `Relationship` - связь между сущностями с типом, рассуждением и контекстом
- `KnowledgeGraph` - контейнер для сущностей и связей

### 3. `generator.py` - Интерфейс генерации LLM
Предоставляет интерфейс для работы с языковыми моделями через различные API-клиенты.

**Основные компоненты:**
- `Generator` - основной класс, который генерирует Pydantic-объекты с помощью LLM
- Система самокоррекции для улучшения качества генерации
- Логика повторных попыток и обработки ошибок

### 4. `google_gen.py`, `lcpp_gen.py`, `open_router_gen.py` - Клиенты LLM
Различные реализации клиентов для взаимодействия с языковыми моделями:
- `GoogleGenAI` - для моделей Google Gemini
- `LlamaCppGenAI` - для локальных моделей через llama.cpp
- `OpenRouterGenAI` - для моделей через OpenRouter API

### 5. `entity_normalizer.py` - Нормализация сущностей
Служит для нормализации имен сущностей с использованием нечеткого сопоставления.

**Основные функции:**
- Хранение нормализованных имен в SQLite-базе
- Нечеткое сопоставление похожих имен
- Объединение дубликатов сущностей
- Обновление описаний сущностей (новая функциональность)

### 6. `neo4j_manager.py` - Управление Neo4j
Обрабатывает сохранение графа знаний в базу данных Neo4j.

**Основные функции:**
- Генерация Cypher-запросов для создания узлов и связей
- Выполнение операций MERGE для избежания дубликатов
- Интеграция с нормализатором сущностей
- Управление свойствами узлов и связей

### 7. `logger_config.py` - Централизованная система логирования
Создает единый интерфейс для логирования во всем приложении.

## Работа пайплайна

### 1. Загрузка и анализ текста
- Скрипт `parse.py` читает текстовые файлы из списка (например, `both.txt`)
- Загружает русскую модель spaCy (`ru_core_news_lg`) для анализа текста
- Извлекает потенциальные имена сущностей из текста

### 2. Получение контекста
- Использует `entity_normalizer` для поиска уже известных сущностей
- Собирает соответствующую информацию для улучшения генерации

### 3. Генерация графа знаний
- Отправляет текст и инструкции в LLM через `generator`
- LLM генерирует структурированный объект `KnowledgeGraph`
- Следует строгим правилам моделирования графа

### 4. Нормализация имен
- Использует `entity_normalizer` для объединения похожих имен
- Применяет нечеткое сопоставление для обнаружения дубликатов
- Обновляет описания сущностей, если они были нулевыми

### 5. Сохранение результатов
- Генерирует Cypher-запросы для Neo4j
- Сохраняет узлы и связи с использованием операций MERGE
- Добавляет информацию о файле-источнике к связям

## Правила моделирования графа

### Сущности (Entities):
- `name`: Каноническое имя на языке оригинала (Русский)
- `label`: Английский язык, PascalCase, Единственное число
- Разрешенные типы: [Person, Organization, Country, City, Role, Event, Document, Resource]

### Связи (Relationships):
- `type`: Английский язык, UPPER_SNAKE_CASE, описывающий действие
- `reasoning`: Краткое объяснение причины существования связи
- Примеры: HELD_POSITION, SIGNED_CONTRACT, MADE_STATEMENT, LOCATED_IN

### Свойства (Properties):
- `context`: Дополнительный контекст для узлов и связей

## Запуск проекта

1. Убедитесь, что установлены все зависимости
2. Настройте API-ключи в файле `.env`
3. Установите русскую модель spaCy: `python -m spacy download ru_core_news_lg`
4. Запустите `python parse.py` для обработки файлов из `both.txt`

## Особенности реализации

1. **Нормализация описаний**: Если сущность встречается без описания, в базе сохраняется NULL, но при последующем появлении этой же сущности с описанием, описание обновляется.

2. **Безопасная обработка**: Используются механизмы повторных попыток и обработки ошибок везде, где это необходимо.

3. **Централизованное логирование**: Все модули используют единую систему логирования.

4. **Параллельная обработка**: Возможна параллельная обработка файлов с использованием `thread_map`.

## Технологии

- Python 3.13+
- Neo4j - для хранения графа знаний
- spaCy - для анализа текста
- Pydantic - для валидации данных
- Google Gemini / OpenRouter / Llama.cpp - для генерации
- SQLite - для хранения нормализованных сущностей